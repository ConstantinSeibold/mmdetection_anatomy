{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"./..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6hD0mmMixT0p",
    "outputId": "221dad3c-5ef8-4094-e07e-289f333f7bb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "torch version: 2.0.1 cuda: False\n",
      "mmdetection: 3.3.0\n",
      "mmcv: 2.0.0rc4\n",
      "mmengine: 0.10.4\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(\"torch version:\",torch.__version__, \"cuda:\",torch.cuda.is_available())\n",
    "\n",
    "# Check MMDetection installation\n",
    "import mmdet\n",
    "print(\"mmdetection:\",mmdet.__version__)\n",
    "\n",
    "# Check mmcv installation\n",
    "import mmcv\n",
    "print(\"mmcv:\",mmcv.__version__)\n",
    "\n",
    "# Check mmengine installation\n",
    "import mmengine\n",
    "print(\"mmengine:\",mmengine.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo',\n",
       " 'tools',\n",
       " 'docker',\n",
       " 'pytest.ini',\n",
       " 'toy_dataset',\n",
       " 'LICENSE',\n",
       " 'requirements.txt',\n",
       " '.pre-commit-config-zh-cn.yaml',\n",
       " '.pre-commit-config.yaml',\n",
       " 'CITATION.cff',\n",
       " '.owners.yml',\n",
       " 'file_processing',\n",
       " 'projects',\n",
       " 'resources',\n",
       " 'checkpoints',\n",
       " 'out.png',\n",
       " 'tests',\n",
       " 'MANIFEST.in',\n",
       " 'requirements',\n",
       " 'docs',\n",
       " 'README_zh-CN.md',\n",
       " '.readthedocs.yml',\n",
       " 'README.md',\n",
       " '__MACOSX',\n",
       " 'test.png',\n",
       " 'setup.py',\n",
       " 'inference_scripts',\n",
       " '.gitignore',\n",
       " 'mmdet.egg-info',\n",
       " 'configs',\n",
       " '.github',\n",
       " '.dev_scripts',\n",
       " 'setup.cfg',\n",
       " '.ipynb_checkpoints',\n",
       " '.git',\n",
       " 'model-index.yml',\n",
       " '.circleci',\n",
       " 'dataset-index.yml',\n",
       " 'mmdet']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gi9zw03oM4CH"
   },
   "source": [
    "## Perform Inference with An MMDetection Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8M5KUnX7Np3h",
    "outputId": "71de79c0-9f7e-4cae-f810-5c0a20fe9be8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth\n"
     ]
    }
   ],
   "source": [
    "import mmcv\n",
    "import mmengine\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmdet.utils import register_all_modules\n",
    "# Choose to use a config and initialize the detector\n",
    "config_file = 'configs/mask_rcnn/mask-rcnn_r50-caffe_fpn_ms-poly-3x_coco.py'\n",
    "# Setup a checkpoint file to load\n",
    "checkpoint_file = 'checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'\n",
    "\n",
    "# register all modules in mmdet into the registries\n",
    "register_all_modules()\n",
    "\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_detector(config_file, checkpoint_file, device='cpu')  # or device='cuda:0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hamZrlnH-YDD"
   },
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "cfg = Config.fromfile('./configs/mask_rcnn/mask-rcnn_r50-caffe_fpn_ms-poly-1x_coco.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mmdet.datasets.transforms import (AutoAugment, AutoContrast, Brightness,\n",
    "                                       Color, Contrast, Equalize, Invert,\n",
    "                                       Posterize, RandAugment, Rotate,\n",
    "                                       Sharpness, ShearX, ShearY, Solarize,\n",
    "                                       SolarizeAdd, TranslateX, TranslateY)\n",
    "\n",
    "from mmdet.datasets import CocoDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/02 15:42:51 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - balloon is not a meta file, simply parsed as meta information\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root = './toy_dataset/balloon'\n",
    "metainfo = dict(classes=('balloon'), task_name='balloon')\n",
    "from mmengine import Config\n",
    "file_name = 'configs/mask2former/mask2former_r50_8xb2-lsj-50e_coco.py'\n",
    "cfg = Config.fromfile(file_name)\n",
    "\n",
    "dataset = CocoDataset(\n",
    "            data_root=\"toy_dataset/balloon/\",\n",
    "            data_prefix=dict(img='train/'),\n",
    "            metainfo = metainfo,\n",
    "            ann_file='balloon_train.json',\n",
    "            filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
    "            pipeline=[],\n",
    "            serialize_data=False,\n",
    "            lazy_init=False)\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gaussian_noise',\n",
       " 'shot_noise',\n",
       " 'impulse_noise',\n",
       " 'defocus_blur',\n",
       " 'glass_blur',\n",
       " 'motion_blur',\n",
       " 'zoom_blur',\n",
       " 'snow',\n",
       " 'frost',\n",
       " 'fog',\n",
       " 'brightness',\n",
       " 'contrast',\n",
       " 'elastic_transform',\n",
       " 'pixelate',\n",
       " 'jpeg_compression']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imagecorruptions import get_corruption_names\n",
    "get_corruption_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'CocoDataset',\n",
       " 'data_root': 'data/coco/',\n",
       " 'ann_file': 'annotations/instances_train2017.json',\n",
       " 'data_prefix': {'img': 'train2017/',\n",
       "  'seg': 'annotations/panoptic_train2017/'},\n",
       " 'filter_cfg': {'filter_empty_gt': True, 'min_size': 32},\n",
       " 'pipeline': [{'type': 'LoadImageFromFile',\n",
       "   'to_float32': True,\n",
       "   'backend_args': None},\n",
       "  {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True},\n",
       "  {'type': 'RandomFlip', 'prob': 0.5},\n",
       "  {'type': 'RandomResize',\n",
       "   'scale': (1024, 1024),\n",
       "   'ratio_range': (0.1, 2.0),\n",
       "   'resize_type': 'Resize',\n",
       "   'keep_ratio': True},\n",
       "  {'type': 'RandomCrop',\n",
       "   'crop_size': (1024, 1024),\n",
       "   'crop_type': 'absolute',\n",
       "   'recompute_bbox': True,\n",
       "   'allow_negative_crop': True},\n",
       "  {'type': 'FilterAnnotations',\n",
       "   'min_gt_bbox_wh': (1e-05, 1e-05),\n",
       "   'by_mask': True},\n",
       "  {'type': 'PackDetInputs'}],\n",
       " 'backend_args': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.train_dataloader.dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    cfg.train_dataloader.dataset = dict(\n",
    "            type = 'CocoDataset',\n",
    "            data_prefix=dict(img='train'),\n",
    "            data_root=data_root,\n",
    "            ann_file='balloon_train.json',\n",
    "            metainfo=metainfo,\n",
    "            filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
    "            pipeline= [\n",
    "                {'type': 'LoadImageFromFile',\n",
    "                   'to_float32': True,\n",
    "                   'backend_args': None},\n",
    "                   {'type': 'LoadAnnotations',\n",
    "                            'with_bbox': True,\n",
    "                            'with_mask': True,\n",
    "                            'poly2mask': True},\n",
    "                  {'type': 'FilterAnnotations',\n",
    "                   'min_gt_bbox_wh': (1e-05, 1e-05),\n",
    "                   'by_mask': True},\n",
    "                  {'type': 'PackDetInputs'}\n",
    "            ],\n",
    "            serialize_data=False,\n",
    "            lazy_init=False)\n",
    "\n",
    "    if False:\n",
    "        {'type': 'RandomElasticDeformation',\n",
    "                            'min_sigma': 25,\n",
    "                            'max_sigma': 26,\n",
    "                            'min_points': 3,\n",
    "                            'max_points': 4},\n",
    "        {'type': 'RandomColorFormCutOutAlpha',\n",
    "                            \"n_holes\": 9,\n",
    "                            \"cutout_shape\": [(128,128)],\n",
    "                            \"fill_min\": 0, \n",
    "                            \"fill_max\": 255,\n",
    "                            \"alpha_min\":0.2,\n",
    "                            \"alpha_max\":0.8\n",
    "                    },\n",
    "        {'type': 'PhotoMetricDistortion',\n",
    "                            \"brightness_delta\": 0, \n",
    "                            \"contrast_range\": 0, \n",
    "                            \"saturation_range\": 0, \n",
    "                            \"hue_delta\": 0, \n",
    "                    },\n",
    "        {'type': 'Corrupt',\n",
    "                            \"corruption\": \"jpeg_compression\",\n",
    "                            \"severity\": 1,\n",
    "                        }\n",
    "        \n",
    "        \"Corrupt\"\n",
    "        if False:\n",
    "            'gaussian_noise',\n",
    "            'shot_noise',\n",
    "            'impulse_noise',\n",
    "            'defocus_blur',\n",
    "            'motion_blur',\n",
    "            'zoom_blur',\n",
    "            'snow',\n",
    "            'frost',\n",
    "            'fog',\n",
    "            'brightness',\n",
    "            'contrast',\n",
    "            'elastic_transform',\n",
    "            'pixelate',\n",
    "            'jpeg_compression'\n",
    "\n",
    "        \"PhotoMetricDistortion\"\n",
    "        if False:\n",
    "            \"brightness_delta\"\n",
    "            \"contrast_range\"\n",
    "            \"saturation_range\"\n",
    "            \"hue_delta\"\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "img_scales = [\n",
    "            (384, 384),\n",
    "            (512, 512),\n",
    "            (640, 640),\n",
    "            (768, 768),\n",
    "    ]\n",
    "\n",
    "#Corrupt\n",
    "#PhotoMetricDistortion\n",
    "\n",
    "cfg.train_dataloader.dataset = dict(\n",
    "            type = 'CocoDataset',\n",
    "            data_prefix=dict(img='train'),\n",
    "            data_root=data_root,\n",
    "            ann_file='balloon_train.json',\n",
    "            metainfo=metainfo,\n",
    "            filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
    "            pipeline= [\n",
    "                {'type': 'LoadImageFromFile',\n",
    "                       'to_float32': True,\n",
    "                       'backend_args': None},\n",
    "                {'type': 'LoadAnnotations',\n",
    "                    'with_bbox': True,\n",
    "                    'with_mask': True,\n",
    "                    'poly2mask': True\n",
    "                },\n",
    "                {'type': 'RandomChoiceResize',\n",
    "                'scales': img_scales,\n",
    "                'keep_ratio': False\n",
    "                },\n",
    "                {\"type\": \"RandomRandAugment\",\n",
    "                 \"aug_space\": [\n",
    "                     [\n",
    "                         {\"type\": \"RandomColorFormCutOut\",\n",
    "                         \"n_holes\": (0,4),\n",
    "                         \"cutout_shape\": [(16,16),(24,24),(32,32),(48,48),(64,64),(72,72)]\n",
    "                        },\n",
    "                     ],\n",
    "                     [\n",
    "                        {\"type\": \"RandomColorFormCutOutAlpha\",\n",
    "                         \"n_holes\": (0,4),\n",
    "                         \"cutout_shape\": [(16,16),(24,24),(32,32),(48,48),(64,64),(72,72)]\n",
    "                        },\n",
    "                     ],\n",
    "                     [\n",
    "                         {'type': 'RandomElasticDeformation',\n",
    "                            'min_sigma': 0,\n",
    "                            'max_sigma': 26,\n",
    "                            'min_points': 1,\n",
    "                            'max_points': 4},\n",
    "                     ],\n",
    "                     [\n",
    "                         {'type': 'Corrupt',\n",
    "                            \"corruption\": \"gaussian_noise\",\n",
    "                            \"severity\": 1,\n",
    "                        }\n",
    "                     ],\n",
    "                     [\n",
    "                         {'type': 'Corrupt',\n",
    "                            \"corruption\": \"shot_noise\",\n",
    "                            \"severity\": 1,\n",
    "                        }\n",
    "                     ],\n",
    "                     [\n",
    "                         {'type': 'Corrupt',\n",
    "                            \"corruption\": \"impulse_noise\",\n",
    "                            \"severity\": 1,\n",
    "                        }\n",
    "                     ],\n",
    "                     [\n",
    "                         {'type': 'Corrupt',\n",
    "                            \"corruption\": \"defocus_blur\",\n",
    "                            \"severity\": 1,\n",
    "                        }\n",
    "                     ],\n",
    "                     [\n",
    "                         {'type': 'Corrupt',\n",
    "                            \"corruption\": \"motion_blur\",\n",
    "                            \"severity\": 1,\n",
    "                        }\n",
    "                     ],\n",
    "                     [\n",
    "                         {'type': 'Corrupt',\n",
    "                            \"corruption\": \"zoom_blur\",\n",
    "                            \"severity\": 1,\n",
    "                        }\n",
    "                     ],\n",
    "                     [\n",
    "                         {'type': 'Corrupt',\n",
    "                            \"corruption\": \"snow\",\n",
    "                            \"severity\": 1,\n",
    "                        }\n",
    "                     ],\n",
    "                     [\n",
    "                         {'type': 'Corrupt',\n",
    "                            \"corruption\": \"frost\",\n",
    "                            \"severity\": 1,\n",
    "                        }\n",
    "                     ],\n",
    "                     [\n",
    "                         {'type': 'Corrupt',\n",
    "                            \"corruption\": \"fog\",\n",
    "                            \"severity\": 1,\n",
    "                        }\n",
    "                     ],\n",
    "                     [\n",
    "                         {'type': 'Corrupt',\n",
    "                            \"corruption\": \"brightness\",\n",
    "                            \"severity\": 1,\n",
    "                        }\n",
    "                     ],\n",
    "                     [\n",
    "                         {'type': 'Corrupt',\n",
    "                            \"corruption\": \"contrast\",\n",
    "                            \"severity\": 1,\n",
    "                        }\n",
    "                     ],\n",
    "                     [\n",
    "                         {'type': 'Corrupt',\n",
    "                            \"corruption\": \"elastic_transform\",\n",
    "                            \"severity\": 1,\n",
    "                        }\n",
    "                     ],\n",
    "                     [\n",
    "                         {'type': 'Corrupt',\n",
    "                            \"corruption\": \"pixelate\",\n",
    "                            \"severity\": 1,\n",
    "                        }\n",
    "                     ],\n",
    "                     [\n",
    "                         {'type': 'Corrupt',\n",
    "                            \"corruption\": \"jpeg_compression\",\n",
    "                            \"severity\": 1,\n",
    "                        }\n",
    "                     ],\n",
    "                     [\n",
    "                         {'type': 'PhotoMetricDistortion',\n",
    "                            \"brightness_delta\": 32,\n",
    "                            \"contrast_range\": (0.5, 1.5),\n",
    "                            \"saturation_range\": (0.5, 1.5),\n",
    "                            \"hue_delta\": 18\n",
    "                        }\n",
    "                     ],\n",
    "                     [dict(type='Invert')], \n",
    "                     [dict(type='Solarize')],\n",
    "                     [dict(type='SolarizeAdd')], \n",
    "                     [dict(type='Color')],\n",
    "                     [dict(type='Contrast')], \n",
    "                     [dict(type='Brightness')],\n",
    "                     [dict(type='Sharpness')], \n",
    "                     [dict(type='Rotate')],\n",
    "                     [dict(type='ShearX')],\n",
    "                     [dict(type='ShearY')], \n",
    "                     [dict(type='TranslateX')],\n",
    "                     [dict(type='TranslateY')]\n",
    "                 ],\n",
    "                 \"aug_num\": 6,\n",
    "                 \n",
    "                },\n",
    "                \n",
    "            ],\n",
    "            serialize_data=False,\n",
    "            lazy_init=False)\n",
    "                                                  \n",
    "img_scale = (640,640)\n",
    "train_pipeline = [\n",
    "    dict(type=\"CutMix\",\n",
    "        ratio_range =  (0.5,1.5),\n",
    "        flip_ratio =  0.5,\n",
    "        pad_val =  114.0,\n",
    "        max_iters =  15,\n",
    "        bbox_clip_border =  True ,\n",
    "        crop_min= 64,\n",
    "        crop_max= 256,\n",
    "        p = 0.5\n",
    "        ),\n",
    "    dict(type='PackDetInputs')\n",
    "]\n",
    "\n",
    "cfg.train_dataloader.dataset = dict(\n",
    "    type='MultiImageMixDataset',\n",
    "    dataset= cfg.train_dataloader.dataset,\n",
    "    pipeline=train_pipeline\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5215763361556962"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "[                                                  ] 0/61, elapsed: 0s, ETA:1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mmdet.models.utils import mask2ndarray\n",
    "from mmdet.registry import DATASETS, VISUALIZERS\n",
    "from mmdet.structures.bbox import BaseBoxes\n",
    "from mmengine.registry import init_default_scope\n",
    "from mmengine.utils import ProgressBar\n",
    "\n",
    "import os.path as osp\n",
    "\n",
    "# register all modules in mmdet into the registries\n",
    "init_default_scope('mmdet')\n",
    "\n",
    "dataset = DATASETS.build(\n",
    "    cfg.train_dataloader.dataset\n",
    ")\n",
    "\n",
    "visualizer = VISUALIZERS.build(\n",
    "    dict(\n",
    "        type='DetLocalVisualizer',\n",
    "        vis_backends=[dict(type='LocalVisBackend')],\n",
    "        name='visualizer'\n",
    "    )\n",
    ")\n",
    "visualizer.dataset_meta = dataset.metainfo\n",
    "\n",
    "progress_bar = ProgressBar(len(dataset))\n",
    "\n",
    "# item = dataset[5]\n",
    "\n",
    "for item in dataset:\n",
    "    print(1)\n",
    "    img = item['inputs'].permute(1, 2, 0).numpy()\n",
    "    data_sample = item['data_samples'].numpy()\n",
    "    gt_instances = data_sample.gt_instances\n",
    "    img_path = osp.basename(item['data_samples'].img_path)\n",
    "\n",
    "\n",
    "    img = img[..., [2, 1, 0]]  # bgr to rgb\n",
    "    gt_bboxes = gt_instances.get('bboxes', None)\n",
    "    if gt_bboxes is not None and isinstance(gt_bboxes, BaseBoxes):\n",
    "        gt_instances.bboxes = gt_bboxes.tensor\n",
    "    gt_masks = gt_instances.get('masks', None)\n",
    "    if gt_masks is not None:\n",
    "        masks = mask2ndarray(gt_masks)\n",
    "        gt_instances.masks = masks.astype(bool)\n",
    "    data_sample.gt_instances = gt_instances\n",
    "\n",
    "    visualizer.add_datasample(\n",
    "            osp.basename(img_path),\n",
    "            img,\n",
    "            data_sample,\n",
    "            draw_pred=True,\n",
    "            out_file=\"out.png\")\n",
    "\n",
    "    visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import necessary libraries\n",
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mmdet.models.utils import mask2ndarray\n",
    "from mmdet.registry import DATASETS, VISUALIZERS\n",
    "from mmdet.structures.bbox import BaseBoxes\n",
    "from mmengine.registry import init_default_scope\n",
    "from mmengine.utils import ProgressBar\n",
    "\n",
    "import os.path as osp\n",
    "\n",
    "# register all modules in mmdet into the registries\n",
    "init_default_scope('mmdet')\n",
    "\n",
    "dataset = DATASETS.build(\n",
    "    cfg.train_dataloader.dataset\n",
    ")\n",
    "\n",
    "visualizer = VISUALIZERS.build(\n",
    "    dict(\n",
    "        type='DetLocalVisualizer',\n",
    "        vis_backends=[dict(type='LocalVisBackend')],\n",
    "        name='visualizer'\n",
    "    )\n",
    ")\n",
    "visualizer.dataset_meta = dataset.metainfo\n",
    "\n",
    "progress_bar = ProgressBar(len(dataset))\n",
    "\n",
    "item = dataset[0]\n",
    "\n",
    "#for item in dataset:\n",
    "\n",
    "img = item['inputs'].permute(1, 2, 0).numpy()\n",
    "data_sample = item['data_samples'].numpy()\n",
    "gt_instances = data_sample.gt_instances\n",
    "img_path = osp.basename(item['data_samples'].img_path)\n",
    "\n",
    "\n",
    "img = img[..., [2, 1, 0]]  # bgr to rgb\n",
    "gt_bboxes = gt_instances.get('bboxes', None)\n",
    "if gt_bboxes is not None and isinstance(gt_bboxes, BaseBoxes):\n",
    "    gt_instances.bboxes = gt_bboxes.tensor\n",
    "gt_masks = gt_instances.get('masks', None)\n",
    "if gt_masks is not None:\n",
    "    masks = mask2ndarray(gt_masks)\n",
    "    gt_instances.masks = masks.astype(bool)\n",
    "data_sample.gt_instances = gt_instances\n",
    "\n",
    "visualizer.add_datasample(\n",
    "        osp.basename(img_path),\n",
    "        img,\n",
    "        data_sample,\n",
    "        draw_pred=True,\n",
    "    \n",
    "        out_file=\"test.png\")\n",
    "\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# test RandAugment equipped with Rotate\n",
    "aug_space = [[\n",
    "    dict(type='Rotate', prob=1.0, level=10, reversal_prob=0.0)\n",
    "]]\n",
    "transform_rand = RandAugment(aug_space=aug_space, aug_num=1)\n",
    "results_rand = transform_rand(copy.deepcopy(self.results_mask))\n",
    "transform_rotate = Rotate(prob=1.0, level=10, reversal_prob=0.0)\n",
    "\n",
    "results_rotated = transform_rotate(copy.deepcopy(self.results_mask))\n",
    "\n",
    "check_result_same(results_rotated, results_rand, self.check_keys)\n",
    "\n",
    "# test RandAugment equipped with default augmentation space\n",
    "transform_rand = RandAugment()\n",
    "transform_rand(copy.deepcopy(self.results_mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "111W_oZV_3wa",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Train a new detector\n",
    "\n",
    "Finally, lets initialize the dataset and detector, then train a new detector!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JiqDnPdAMGyg",
    "outputId": "0de25679-3541-488e-eceb-5b5400f92745"
   },
   "outputs": [],
   "source": [
    "!python tools/train.py {config}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vYQF5K2NqqI"
   },
   "source": [
    "### Understand the log\n",
    "From the log, we can have a basic understanding on the training process and know how well the detector is trained.\n",
    "\n",
    "First, since the dataset we are using is small, we loaded a Mask R-CNN model and finetune it for detection. Because the original Mask R-CNN is trained on COCO dataset that contains 80 classes but KITTI Tiny dataset only have 3 classes. Therefore, the last FC layers of the pre-trained Mask R-CNN for classification and regression have different weight shape and are not used. The pre-trained weights of mask prediction layer `mask_head.conv_logits` also does not matches the current model and is not used due to similar reason.\n",
    "\n",
    "Third, after training, the detector is evaluated by the default COCO-style evaluation. The results show that the detector achieves 79.6 bbox AP and 81.5 mask AP on the val dataset, not bad!\n",
    "\n",
    " We can also check the tensorboard to see the curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbLNlJR-RYYd"
   },
   "outputs": [],
   "source": [
    "%pip install tensorboard  -i https://mirrors.ustc.edu.cn/pypi/web/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PW2NAam_7irv"
   },
   "outputs": [],
   "source": [
    "# load tensorboard in jupyter notebook\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4G9MCbL2RYYd"
   },
   "outputs": [],
   "source": [
    "# see curves in tensorboard\n",
    "# if you see <IPython.core.display.HTML object> please run it again\n",
    "%tensorboard --logdir tutorial_exps/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfQ-yspZLuuI"
   },
   "source": [
    "## Test the Trained Detector\n",
    "\n",
    "After finetuning the detector, let's visualize the prediction results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_MuZurfGLq0p",
    "outputId": "4b25759c-8e22-405e-a061-3abc44e38043"
   },
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "img = mmcv.imread('./ballondatasets/balloon/train/7178882742_f090f3ce56_k.jpg',channel_order='rgb')\n",
    "checkpoint_file = 'tutorial_exps/epoch_12.pth'\n",
    "model = init_detector(cfg, checkpoint_file, device='cpu')\n",
    "new_result = inference_detector(model, img)\n",
    "print(new_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "7SSTauCURYYe",
    "outputId": "3becb5ea-cb4e-44f6-d93d-c10194a2263b"
   },
   "outputs": [],
   "source": [
    "from mmengine.visualization import Visualizer\n",
    "# get built visualizer\n",
    "visualizer_now = Visualizer.get_current_instance()\n",
    "# the dataset_meta is loaded from the checkpoint and\n",
    "# then pass to the model in init_detector\n",
    "visualizer_now.dataset_meta = model.dataset_meta\n",
    "# show the results\n",
    "visualizer_now.add_datasample(\n",
    "    'new_result',\n",
    "    img,\n",
    "    data_sample=new_result,\n",
    "    draw_gt=False,\n",
    "    wait_time=0,\n",
    "    out_file=None,\n",
    "    pred_score_thr=0.5\n",
    ")\n",
    "visualizer_now.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rzruCwFgPXm"
   },
   "source": [
    "## What to Do Next?\n",
    "\n",
    "So far, we have learnt how to test and train Mask R-CNN. To further explore the segmentation task, you could do several other things as shown below:\n",
    "\n",
    "- Try cascade methods, e.g., [Cascade Mask R-CNN](https://github.com/open-mmlab/mmdetection/tree/master/configs/cascade_rcnn) and [HTC](https://github.com/open-mmlab/mmdetection/tree/master/configs/htc) in [MMDetection model zoo](https://github.com/open-mmlab/mmdetection/blob/master/docs/en/model_zoo.md). They are powerful detectors that are ranked high in many benchmarks, e.g., COCO dataset.\n",
    "- Try single-stage methods, e.g., [K-Net](https://github.com/ZwwWayne/K-Net) and [Dense-RepPoints](https://github.com/justimyhxu/Dense-RepPoints). These two algorithms are based on MMDetection. Box-free instance segmentation is a new trend in the instance segmentation community.\n",
    "- Try semantic segmentation. Semantic segmentation is also a popular task with wide applications. You can explore [MMSegmentation](https://github.com/open-mmlab/mmsegmentation/); we also provide a [colab tutorial](https://github.com/open-mmlab/mmsegmentation/blob/master/demo/MMSegmentation_Tutorial.ipynb) for semantic segmentation using MMSegmentation.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "8868640c17582ff5a3e06365ba2fb344ce697cf42d4745ae8b85a9738303c037"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
